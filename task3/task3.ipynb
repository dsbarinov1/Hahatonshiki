{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классическое решение"
      ],
      "metadata": {
        "id": "RIh4Z2uhmJgf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6GCSD4gHblnA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9taPKDlkspR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "# Tools for creating ngrams and vectorizing input data\n",
        "from gensim.models import Word2Vec, Phrases\n",
        "\n",
        "# Configs\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "sns.set(style=\"whitegrid\")\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjkObd5ikspU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"task-3-dataset.csv\") # Считываем данные\n",
        "df2 = pd.read_csv(\"test50.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbXTFPePkspV",
        "outputId": "448d06b9-ee59-4f4f-9491-ffeb6170c4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy3) (0.7.2)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.10/dist-packages (from pymorphy3) (2.4.417150.4580142)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXNe4LxvkspV"
      },
      "outputs": [],
      "source": [
        "import pymorphy3\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "# Функция загрузки стопслов\n",
        "def downloads_():\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    from nltk.corpus import stopwords\n",
        "# Функция обработки текта\n",
        "def foo(review, morph):\n",
        "    # Обработка текста отзыва. Оставляем только буквы, приводим к нижнему регистру\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    review = re.sub('[^а-яА-Я]', ' ', review)\n",
        "    review = review.lower()\n",
        "    # Отделяем слова\n",
        "    review = review.split()\n",
        "    # Избавляемся от стоп-слов(предлоги,союзы, частицы, не несущие семантической нагрузки)\n",
        "    review = [word for word in review if not word in set(stopwords.words('russian'))]\n",
        "    # Лемматизируем(для русского языка в явном виде нет, но пока тк)\n",
        "    # В явном виде лемматизации нет для русского языка,  SNOWBALL STEMMER как вариант\n",
        "    lemmatized_words = [morph.normal_forms(word)[0] for word in review]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "unnoDv1xkspW",
        "outputId": "2f1a3617-ee81-49e4-f545-5c3cbcc18792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      -\n",
              "1      +\n",
              "2      -\n",
              "3      -\n",
              "4      +\n",
              "      ..\n",
              "205    +\n",
              "206    +\n",
              "207    -\n",
              "208    -\n",
              "209    +\n",
              "Name: разметка, Length: 210, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>разметка</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>210 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Разделим данные, пока нет тестовых\n",
        "from sklearn.model_selection import train_test_split\n",
        "# dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(df['отзывы'], df['разметка'], test_size=0.2, random_state=42)\n",
        "dataset_train = df['отзывы']\n",
        "train_data_label = df['разметка']\n",
        "\n",
        "dataset_test = df2[\"Отзывы\"]\n",
        "test_data_label = df2[\"разметка\"]\n",
        "\n",
        "train_data_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpj4BOSSkspY",
        "outputId": "8d079e1c-ea31-4831-dc6a-8ba08dc02872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Сформируем тестовый и трейновый словари\n",
        "corpus_train = []\n",
        "corpus_test  = []\n",
        "\n",
        "downloads_()\n",
        "for i in range(dataset_train.shape[0]):\n",
        "    review = dataset_train.iloc[i]\n",
        "    review = foo(review, morph)\n",
        "    corpus_train.append(review)\n",
        "\n",
        "for j in range(dataset_test.shape[0]):\n",
        "    review = dataset_test.iloc[j]\n",
        "    review = foo(review, morph)\n",
        "    corpus_test.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxmmxPilkspY"
      },
      "outputs": [],
      "source": [
        "# Векторизуем с помощью TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
        "\n",
        "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
        "tfidf_vec_test = tfidf_vec.transform(corpus_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdH2uwaXkspZ"
      },
      "outputs": [],
      "source": [
        "# Обучаем\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "linear_svc = LinearSVC(C=0.5, random_state=42)\n",
        "linear_svc.fit(tfidf_vec_train, train_data_label)\n",
        "\n",
        "predict = linear_svc.predict(tfidf_vec_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rSUggF9kspa",
        "outputId": "82da490b-1553-4a45-bc20-6efd91b8ca11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.58      0.83      0.68        23\n",
            "    Positive       0.76      0.48      0.59        27\n",
            "\n",
            "    accuracy                           0.64        50\n",
            "   macro avg       0.67      0.65      0.63        50\n",
            "weighted avg       0.68      0.64      0.63        50\n",
            "\n",
            "Confusion Matrix: \n",
            " [[19  4]\n",
            " [14 13]]\n",
            "Accuracy: \n",
            " 0.64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "print(\"Classification Report: \\n\", classification_report(test_data_label, predict,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict))\n",
        "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTCwNHz4kspa",
        "outputId": "72f01e8f-d04c-4286-85eb-1a2752a060da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.52      0.61      0.56        23\n",
            "    Positive       0.61      0.52      0.56        27\n",
            "\n",
            "    accuracy                           0.56        50\n",
            "   macro avg       0.56      0.56      0.56        50\n",
            "weighted avg       0.57      0.56      0.56        50\n",
            "\n",
            "Confusion Matrix: \n",
            " [[14  9]\n",
            " [13 14]]\n",
            "Accuracy: \n",
            " 0.56\n"
          ]
        }
      ],
      "source": [
        "# Векторизуем с помощью другого векторизатора\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vec = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
        "count_vec_train = count_vec.fit_transform(corpus_train)\n",
        "count_vec_test = count_vec.transform(corpus_test)\n",
        "\n",
        "linear_svc_count = LinearSVC(C=0.5, random_state=42, max_iter=5000)\n",
        "linear_svc_count.fit(count_vec_train, train_data_label)\n",
        "predict_count = linear_svc_count.predict(count_vec_test)\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_count,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_count))\n",
        "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CYn_YK1kspc",
        "outputId": "6a749951-9fea-4ccb-89b7-20f46882e5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.54      0.61      0.57        23\n",
            "    Positive       0.62      0.56      0.59        27\n",
            "\n",
            "    accuracy                           0.58        50\n",
            "   macro avg       0.58      0.58      0.58        50\n",
            "weighted avg       0.59      0.58      0.58        50\n",
            "\n",
            "Confusion Matrix: \n",
            " [[14  9]\n",
            " [12 15]]\n",
            "Accuracy: \n",
            " 0.58\n"
          ]
        }
      ],
      "source": [
        "# И снова другой векторизатор\n",
        "ind_vec = CountVectorizer(ngram_range=(1, 3), binary=True)\n",
        "ind_vec_train = ind_vec.fit_transform(corpus_train)\n",
        "ind_vec_test = ind_vec.transform(corpus_test)\n",
        "\n",
        "linear_svc_ind = LinearSVC(C=0.5, random_state=42)\n",
        "linear_svc_ind.fit(ind_vec_train, train_data_label)\n",
        "predict_ind = linear_svc_ind.predict(ind_vec_test)\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_ind,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_ind))\n",
        "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_ind))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByjNr68Mkspc",
        "outputId": "77a42e1c-7e08-436e-fbb5-ec3214d7570b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 857) (50, 857)\n"
          ]
        }
      ],
      "source": [
        "# TF_IDF дал лучший результат, используем его, добаим наивный байесовский классификатор\n",
        "tfidf_vec_NB = TfidfVectorizer(ngram_range=(1, 1))\n",
        "tfidf_vec_train_NB = tfidf_vec_NB.fit_transform(corpus_train)\n",
        "\n",
        "tfidf_vec_test_NB = tfidf_vec_NB.transform(corpus_test)\n",
        "\n",
        "print(tfidf_vec_train_NB.toarray().shape, tfidf_vec_test_NB.toarray().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8BIHh90kspc",
        "outputId": "0336ba9c-a51a-423e-8364-19df549aea33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=50000 is greater than n_features=857. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "ch2 = SelectKBest(chi2, k=50000)\n",
        "tfidf_vec_train_NB = ch2.fit_transform(tfidf_vec_train_NB, train_data_label)\n",
        "tfidf_vec_test_NB  = ch2.transform(tfidf_vec_test_NB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAfjOcYakspc",
        "outputId": "6c07ccd3-e352-4a1a-a97a-41ed5460d776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.55      0.96      0.70        23\n",
            "    Positive       0.90      0.33      0.49        27\n",
            "\n",
            "    accuracy                           0.62        50\n",
            "   macro avg       0.73      0.64      0.59        50\n",
            "weighted avg       0.74      0.62      0.58        50\n",
            "\n",
            "Confusion Matrix: \n",
            " [[22  1]\n",
            " [18  9]]\n",
            "Accuracy: \n",
            " 0.62\n"
          ]
        }
      ],
      "source": [
        "feature_names = tfidf_vec_NB.get_feature_names_out()\n",
        "feature_names = [feature_names[i] for i\n",
        "                         in ch2.get_support(indices=True)]\n",
        "feature_names = np.asarray(feature_names)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "multi_clf = MultinomialNB()\n",
        "multi_clf.fit(tfidf_vec_train_NB, train_data_label)\n",
        "predict_NB = multi_clf.predict(tfidf_vec_test_NB)\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_NB,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_NB))\n",
        "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_NB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-Psl_Ewkspd",
        "outputId": "e3adf1a3-11be-46f9-85c8-9904532afd9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.61      0.83      0.70        23\n",
            "    Positive       0.79      0.56      0.65        27\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.70      0.69      0.68        50\n",
            "weighted avg       0.71      0.68      0.68        50\n",
            "\n",
            "Confusion Matrix: \n",
            " [[19  4]\n",
            " [12 15]]\n",
            "Accuracy: \n",
            " 0.68\n"
          ]
        }
      ],
      "source": [
        "count_vec_NB = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
        "count_vec_train_NB = count_vec_NB.fit_transform(corpus_train)\n",
        "count_vec_test_NB = count_vec_NB.transform(corpus_test)\n",
        "\n",
        "multi_clf_count = MultinomialNB()\n",
        "multi_clf_count.fit(count_vec_train_NB, train_data_label)\n",
        "predict_NB_count = multi_clf_count.predict(count_vec_test_NB)\n",
        "\n",
        "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_NB_count,target_names=['Negative','Positive']))\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_NB_count))\n",
        "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_NB_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Квантовое решение"
      ],
      "metadata": {
        "id": "rm9ZlP_ZmGmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NpqzmelcH01",
        "outputId": "9ec37b6d-41f6-4699-e511-ca9ea3fa9da4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "crAkwGS_blnB"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"task-3-dataset.csv\") # Считываем данные\n",
        "df2 = pd.read_csv(\"test50.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kciSExozb36R",
        "outputId": "c487e7fc-d298-49ee-ff7f-26d38ad425b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy3)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg-python, pymorphy3\n",
            "Successfully installed dawg-python-0.7.2 pymorphy3-2.0.2 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w5Y3US_qblnB"
      },
      "outputs": [],
      "source": [
        "import pymorphy3\n",
        "morph = pymorphy3.MorphAnalyzer(lang='ru')\n",
        "# Функция загрузки стопслов\n",
        "def downloads_():\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "# Функция обработки текта\n",
        "def foo(review):\n",
        "    # Обработка текста отзыва. Оставляем только буквы, приводим к нижнему регистру\n",
        "    review = review.lower()\n",
        "    review = review.replace('ё','е')\n",
        "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
        "    review = re.sub('[^а-я]', ' ', review)\n",
        "    # Отделяем слова\n",
        "    review = review.split()\n",
        "    # Избавляемся от стоп-слов(предлоги,союзы, частицы, не несущие семантической нагрузки)\n",
        "    review = [word for word in review if not word in set(stopwords.words('russian'))]\n",
        "    # Лемматизируем(для русского языка в явном виде нет, но пока тк)\n",
        "    # В явном виде лемматизации нет для русского языка,  SNOWBALL STEMMER как вариант\n",
        "    lemmatized_words = [morph.normal_forms(word)[0] for word in review]\n",
        "    lemmatized_text = ' '.join(lemmatized_words)\n",
        "    return lemmatized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W7WgHWLblnC",
        "outputId": "f0995f91-dcc2-4995-c870-6fa4e697bfd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-8c8c52703495>:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df[\"разметка\"].loc[df[\"разметка\"]==\"+\"]=1\n",
            "<ipython-input-46-8c8c52703495>:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df[\"разметка\"].loc[df[\"разметка\"]==\"-\"]=0\n",
            "<ipython-input-46-8c8c52703495>:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df2[\"разметка\"].loc[df2[\"разметка\"]==\"+\"]=1\n",
            "<ipython-input-46-8c8c52703495>:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  df2[\"разметка\"].loc[df2[\"разметка\"]==\"-\"]=0\n"
          ]
        }
      ],
      "source": [
        "# Разделим данные, пока нет тестовых\n",
        "from sklearn.model_selection import train_test_split\n",
        "df[\"разметка\"].loc[df[\"разметка\"]==\"+\"]=1\n",
        "df[\"разметка\"].loc[df[\"разметка\"]==\"-\"]=0\n",
        "df[\"отзывы\"] = df[\"отзывы\"].apply(foo)\n",
        "\n",
        "df2[\"разметка\"].loc[df2[\"разметка\"]==\"+\"]=1\n",
        "df2[\"разметка\"].loc[df2[\"разметка\"]==\"-\"]=0\n",
        "df2[\"Отзывы\"] = df2[\"Отзывы\"].apply(foo)\n",
        "\n",
        "#dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(df['отзывы'], df['разметка'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "co8Gxno3blnC"
      },
      "outputs": [],
      "source": [
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTWfdRXhblnC",
        "outputId": "98c2d9b7-1047-4dc7-bb80-ec108fc2d2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "downloads_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMS0AMqAblnD",
        "outputId": "9ac82dae-ffc1-4454-8553-ad2b2a54584e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tfidf_train: (210, 3884)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tv=TfidfVectorizer(min_df=0.0,max_df=1.0,use_idf=True,ngram_range=(1,3))\n",
        "#transformed train reviews\n",
        "tv_train_reviews=tv.fit_transform(df['отзывы'])\n",
        "#transformed test reviews\n",
        "print('Tfidf_train:',tv_train_reviews.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GjtncEqjblnD"
      },
      "outputs": [],
      "source": [
        "# Применим метод главных компонент для того, чтобы сократить вектор TF-IDF\n",
        "from sklearn.decomposition import PCA\n",
        "def reduce_dimensionality(X, n_components=4): # число кубит\n",
        "    pca = PCA(n_components=n_components)\n",
        "    return pca.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XpwYr1zJblnD"
      },
      "outputs": [],
      "source": [
        "# Обрежем данные\n",
        "X = tv_train_reviews.copy()\n",
        "y = df['разметка']\n",
        "X_reduced = reduce_dimensionality(X)\n",
        "X_train = X_reduced.copy()\n",
        "y_train = y.copy()\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arLrNMAWcOc-",
        "outputId": "e973729f-9d2a-4c84-acd6-186205f3bbcf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit_aer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFoP6IoqcTnT",
        "outputId": "2d1b0cf2-d089-45d7-cf85-5cbe0de2678d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit_aer in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.2.4)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (1.13.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_aer) (5.9.5)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit_aer) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.1.0->qiskit_aer) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit_aer) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit_aer) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit_machine_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs3tQk1hcdbG",
        "outputId": "1eba8861-1d52-4636-adfa-13db79589c2e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: qiskit>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.4)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.4)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (75.1.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.9)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.0->qiskit_machine_learning) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.0->qiskit_machine_learning) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.0->qiskit_machine_learning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-yREoYrEblnD"
      },
      "outputs": [],
      "source": [
        "import qiskit\n",
        "from qiskit_aer import Aer\n",
        "from qiskit.circuit import QuantumCircuit, Parameter\n",
        "from qiskit.primitives import Sampler, Estimator\n",
        "#from qiskit.algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "from qiskit_machine_learning.circuit.library import QNNCircuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7h3qOzsblnE",
        "outputId": "356d2bb9-0951-4833-e84d-d15dfa4f207b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ┌─────────────┐      ░ ┌─┐   \n",
            "   q_0: ┤ Ry(theta_0) ├──■───░─┤M├───\n",
            "        ├─────────────┤┌─┴─┐ ░ └╥┘┌─┐\n",
            "   q_1: ┤ Ry(theta_1) ├┤ X ├─░──╫─┤M├\n",
            "        └─────────────┘└───┘ ░  ║ └╥┘\n",
            "meas: 2/════════════════════════╩══╩═\n",
            "                                0  1 \n"
          ]
        }
      ],
      "source": [
        "# Создадим квантовую схему\n",
        "n_qubits = 2 # Число кубит\n",
        "circuit = QuantumCircuit(n_qubits)\n",
        "# Параметры для схемы\n",
        "params = [Parameter(f'theta_{i}') for i in range(n_qubits * 2)]\n",
        "# Кодирование данных\n",
        "for i in range(n_qubits):\n",
        "    circuit.ry(params[i], i)\n",
        "# Параметризированные вращения\n",
        "for i in range(n_qubits - 1):\n",
        "    circuit.cx(i, i + 1)\n",
        "# Добавляем измерения\n",
        "circuit.measure_all()\n",
        "# Рисуем схему в текстовом формате\n",
        "print(circuit.draw(output='text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SA-R6TtrblnE"
      },
      "outputs": [],
      "source": [
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
        "\n",
        "num_inputs = 4\n",
        "feature_map = ZZFeatureMap(num_inputs)\n",
        "ansatz = RealAmplitudes(num_inputs,reps=1)\n",
        "\n",
        "circuit = QuantumCircuit(num_inputs)\n",
        "circuit.compose(feature_map, inplace=True)\n",
        "circuit.compose(ansatz, inplace=True)\n",
        "\n",
        "def parity(x):\n",
        "    return \"{:b}\".format(x).count(\"1\") % 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YyqsYZcblnE",
        "outputId": "dcafd5c2-3586-40aa-94f1-a60a7c806aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-40a5963b7269>:4: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
            "  sampler = Sampler()\n",
            "<ipython-input-38-40a5963b7269>:5: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        }
      ],
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit.primitives import Sampler\n",
        "\n",
        "sampler = Sampler()\n",
        "sampler_qnn = SamplerQNN(\n",
        "    circuit=circuit,\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    interpret=parity,\n",
        "    output_shape=2,\n",
        "    sampler=sampler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJIDQgPublnE",
        "outputId": "20c6170c-3df3-4ab2-b57e-bbc16939d72e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<qiskit_machine_learning.algorithms.classifiers.neural_network_classifier.NeuralNetworkClassifier at 0x788291001030>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
        "classifier = NeuralNetworkClassifier(\n",
        "    neural_network=sampler_qnn,\n",
        "    loss=\"cross_entropy\",\n",
        "    one_hot=True,\n",
        ")\n",
        "classifier.fit(np.asarray(X_train), np.asarray(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"test50.csv\") # Считываем данные"
      ],
      "metadata": {
        "id": "IwaLvDGrfLmc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv2 = tv.fit_transform(df2['Отзывы'])\n",
        "X_test = tv2.copy()\n",
        "y_test = df2['разметка']\n",
        "X_test = reduce_dimensionality(X_test)"
      ],
      "metadata": {
        "id": "9InVZigifTln"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RpBdW1rVblnE"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = [int(i) for i in y_pred]\n",
        "y_true = [int(i) for i in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-dR8Y6jblnE",
        "outputId": "15bdace9-cb50-481c-e31b-ae0bca6dbc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.48\n",
            "Precision: 0.49\n",
            "Recall: 0.48\n",
            "F1 Score: 0.47\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Вывод точности\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Вывод precision, recall и f1-score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}