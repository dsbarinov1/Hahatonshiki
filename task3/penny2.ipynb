{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec, Phrases\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"task-3-dataset.csv\") # Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer(lang='ru')\n",
    "# Функция загрузки стопслов\n",
    "def downloads_():\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "# Функция обработки текта\n",
    "def foo(review):\n",
    "    # Обработка текста отзыва. Оставляем только буквы, приводим к нижнему регистру\n",
    "    review = review.lower()\n",
    "    review = review.replace('ё','е')\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^а-я]', ' ', review)\n",
    "    # Отделяем слова\n",
    "    review = review.split()\n",
    "    # Избавляемся от стоп-слов(предлоги,союзы, частицы, не несущие семантической нагрузки)\n",
    "    review = [word for word in review if not word in set(stopwords.words('russian'))]\n",
    "    # Лемматизируем(для русского языка в явном виде нет, но пока тк)\n",
    "    # В явном виде лемматизации нет для русского языка,  SNOWBALL STEMMER как вариант\n",
    "    lemmatized_words = [morph.normal_forms(word)[0] for word in review]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные, пока нет тестовых\n",
    "from sklearn.model_selection import train_test_split\n",
    "df[\"разметка\"].loc[df[\"разметка\"]==\"+\"]=1\n",
    "df[\"разметка\"].loc[df[\"разметка\"]==\"-\"]=0\n",
    "df[\"отзывы\"] = df[\"отзывы\"].apply(foo)\n",
    "#dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(df['отзывы'], df['разметка'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fayne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "downloads_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (210, 3884)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv=TfidfVectorizer(min_df=0.0,max_df=1.0,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(df['отзывы'])\n",
    "#transformed test reviews\n",
    "print('Tfidf_train:',tv_train_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим метод главных компонент для того, чтобы сократить вектор TF-IDF\n",
    "from sklearn.decomposition import PCA\n",
    "def reduce_dimensionality(X, n_components=16): # число кубит\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обрежем данные\n",
    "X = tv_train_reviews.copy()\n",
    "y = df['разметка']\n",
    "X_reduced = reduce_dimensionality(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit_aer import Aer\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "from qiskit.primitives import Sampler, Estimator\n",
    "#from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─────────────┐                ░ ┌─┐         \n",
      "   q_0: ┤ Ry(theta_0) ├──■─────────────░─┤M├─────────\n",
      "        ├─────────────┤┌─┴─┐           ░ └╥┘┌─┐      \n",
      "   q_1: ┤ Ry(theta_1) ├┤ X ├──■────────░──╫─┤M├──────\n",
      "        ├─────────────┤└───┘┌─┴─┐      ░  ║ └╥┘┌─┐   \n",
      "   q_2: ┤ Ry(theta_2) ├─────┤ X ├──■───░──╫──╫─┤M├───\n",
      "        ├─────────────┤     └───┘┌─┴─┐ ░  ║  ║ └╥┘┌─┐\n",
      "   q_3: ┤ Ry(theta_3) ├──────────┤ X ├─░──╫──╫──╫─┤M├\n",
      "        └─────────────┘          └───┘ ░  ║  ║  ║ └╥┘\n",
      "meas: 4/══════════════════════════════════╩══╩══╩══╩═\n",
      "                                          0  1  2  3 \n"
     ]
    }
   ],
   "source": [
    "# Создадим квантовую схему\n",
    "n_qubits = 4 # Число кубит\n",
    "circuit = QuantumCircuit(n_qubits)\n",
    "# Параметры для схемы\n",
    "params = [Parameter(f'theta_{i}') for i in range(n_qubits * 2)]\n",
    "# Кодирование данных\n",
    "for i in range(n_qubits):\n",
    "    circuit.ry(params[i], i)\n",
    "# Параметризированные вращения\n",
    "for i in range(n_qubits - 1):\n",
    "    circuit.cx(i, i + 1)\n",
    "# Добавляем измерения\n",
    "circuit.measure_all()\n",
    "# Рисуем схему в текстовом формате\n",
    "print(circuit.draw(output='text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "\n",
    "num_inputs = 4\n",
    "feature_map = ZZFeatureMap(num_inputs)\n",
    "ansatz = RealAmplitudes(num_inputs,reps=1)\n",
    "\n",
    "circuit = QuantumCircuit(num_inputs)\n",
    "circuit.compose(feature_map, inplace=True)\n",
    "circuit.compose(ansatz, inplace=True)\n",
    "\n",
    "def parity(x):\n",
    "    return \"{:b}\".format(x).count(\"1\") % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fayne\\AppData\\Local\\Temp\\ipykernel_29628\\3788435028.py:4: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
      "  sampler = Sampler()\n",
      "C:\\Users\\fayne\\AppData\\Local\\Temp\\ipykernel_29628\\3788435028.py:5: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
      "  sampler_qnn = SamplerQNN(\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit.primitives import Sampler\n",
    "\n",
    "sampler = Sampler()\n",
    "sampler_qnn = SamplerQNN(\n",
    "    circuit=circuit,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    interpret=parity,\n",
    "    output_shape=2,\n",
    "    sampler=sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "QiskitMachineLearningError",
     "evalue": "'Input data has incorrect shape, last dimension is not equal to the number of inputs: 4, but got: 16.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQiskitMachineLearningError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqiskit_machine_learning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralNetworkClassifier\n\u001b[0;32m      2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m NeuralNetworkClassifier(\n\u001b[0;32m      3\u001b[0m     neural_network\u001b[38;5;241m=\u001b[39msampler_qnn,\n\u001b[0;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross_entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     one_hot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\algorithms\\trainable_model.py:199\u001b[0m, in \u001b[0;36mTrainableModel.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warm_start:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\algorithms\\classifiers\\neural_network_classifier.py:116\u001b[0m, in \u001b[0;36mNeuralNetworkClassifier._fit_internal\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    113\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, y)\n\u001b[0;32m    115\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_objective(X, y)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\algorithms\\trainable_model.py:295\u001b[0m, in \u001b[0;36mTrainableModel._minimize\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m    291\u001b[0m     optimizer_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    292\u001b[0m         fun\u001b[38;5;241m=\u001b[39mobjective, x0\u001b[38;5;241m=\u001b[39minitial_point, jac\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mgradient\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m     optimizer_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer_result\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\optimizers\\scipy_optimizer.py:148\u001b[0m, in \u001b[0;36mSciPyOptimizer.minimize\u001b[1;34m(self, fun, x0, jac, bounds)\u001b[0m\n\u001b[0;32m    145\u001b[0m     swapped_deprecated_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxfun\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 148\u001b[0m raw_result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m swapped_deprecated_args:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxfun\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:719\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                            bounds\u001b[38;5;241m=\u001b[39mbounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslsqp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 719\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_slsqp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-constr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    722\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0;32m    723\u001b[0m                                        bounds, constraints,\n\u001b[0;32m    724\u001b[0m                                        callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:374\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[1;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    371\u001b[0m     xu[infbnd[:, \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# ScalarFunction provides function and gradient evaluation\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# gh11403 SLSQP sometimes exceeds bounds by 1 or 2 ULP, make sure this\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# doesn't get sent to the func/grad evaluator.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m wrapped_fun \u001b[38;5;241m=\u001b[39m _clip_x_for_func(sf\u001b[38;5;241m.\u001b[39mfun, new_bounds)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\algorithms\\objective_functions.py:191\u001b[0m, in \u001b[0;36mOneHotObjectiveFunction.objective\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# probabilities is of shape (N, num_outputs)\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_network_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# float(...) is for mypy compliance\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(probs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\algorithms\\objective_functions.py:102\u001b[0m, in \u001b[0;36mObjectiveFunction._neural_network_forward\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# if we get the same weights, we don't compute the forward pass again.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_forward_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_forward_weights))\n\u001b[0;32m    100\u001b[0m ):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# compute forward and cache the results for re-use in backward\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# a copy avoids keeping a reference to the same array, so we are sure we have\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# different arrays on the next iteration.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_forward_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(weights)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\neural_networks\\neural_network.py:227\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    214\u001b[0m     input_data: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m     weights: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m SparseArray:\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of the network.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m        The result of the neural network of the shape (output_shape).\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     input_, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[0;32m    229\u001b[0m     output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(input_, weights_)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit_machine_learning\\neural_networks\\neural_network.py:135\u001b[0m, in \u001b[0;36mNeuralNetwork._validate_input\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m input_, shape\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_inputs:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QiskitMachineLearningError(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data has incorrect shape, last dimension \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not equal to the number of inputs: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_inputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m     )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# add an empty dimension for samples (batch dimension)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     input_ \u001b[38;5;241m=\u001b[39m input_\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mQiskitMachineLearningError\u001b[0m: 'Input data has incorrect shape, last dimension is not equal to the number of inputs: 4, but got: 16.'"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.algorithms import NeuralNetworkClassifier\n",
    "classifier = NeuralNetworkClassifier(\n",
    "    neural_network=sampler_qnn,\n",
    "    loss=\"cross_entropy\",\n",
    "    one_hot=True,\n",
    ")\n",
    "classifier.fit(np.asarray(X_train), np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_pred]\n\u001b[0;32m      3\u001b[0m y_true \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y_test]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = [int(i) for i in y_pred]\n",
    "y_true = [int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Вывод точности\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43my_true\u001b[49m, y_pred)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Вывод precision, recall и f1-score\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Вывод точности\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Вывод precision, recall и f1-score\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обрежем данные\n",
    "X = tv_train_reviews.copy()\n",
    "y = df['разметка']\n",
    "X_reduced = reduce_dimensionality(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_classes = 2\n",
    "margin = 0.15\n",
    "feature_size = 4\n",
    "batch_size = 10\n",
    "lr_adam = 0.01\n",
    "train_split = 0.75\n",
    "# the number of the required qubits is calculated from the number of features\n",
    "num_qubits = int(np.ceil(np.log2(feature_size)))\n",
    "num_layers = 6\n",
    "total_iterations = 100\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    for i in range(num_qubits):\n",
    "        qml.Rot(W[i, 0], W[i, 1], W[i, 2], wires=i)\n",
    "    for j in range(num_qubits - 1):\n",
    "        qml.CNOT(wires=[j, j + 1])\n",
    "    if num_qubits >= 2:\n",
    "        # Apply additional CNOT to entangle the last with the first qubit\n",
    "        qml.CNOT(wires=[num_qubits - 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(weights, feat=None):\n",
    "    qml.AmplitudeEmbedding(feat, range(num_qubits), pad_with=0.0, normalize=True)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "\n",
    "qnodes = []\n",
    "for iq in range(num_classes):\n",
    "    qnode = qml.QNode(circuit, dev, interface=\"torch\")\n",
    "    qnodes.append(qnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(q_circuit, params, feat):\n",
    "    weights = params[0]\n",
    "    bias = params[1]\n",
    "    return q_circuit(weights, feat=feat) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_svm_loss(q_circuits, all_params, feature_vecs, true_labels):\n",
    "    loss = 0\n",
    "    num_samples = len(true_labels)\n",
    "    for i, feature_vec in enumerate(feature_vecs):\n",
    "        # Compute the score given to this sample by the classifier corresponding to the\n",
    "        # true label. So for a true label of 1, get the score computed by classifer 1,\n",
    "        # which distinguishes between \"class 1\" or \"not class 1\".\n",
    "        s_true = variational_classifier(\n",
    "            q_circuits[int(true_labels[i])],\n",
    "            (all_params[0][int(true_labels[i])], all_params[1][int(true_labels[i])]),\n",
    "            feature_vec,\n",
    "        )\n",
    "        s_true = s_true.float()\n",
    "        li = 0\n",
    "\n",
    "        # Get the scores computed for this sample by the other classifiers\n",
    "        for j in range(num_classes):\n",
    "            if j != int(true_labels[i]):\n",
    "                s_j = variational_classifier(\n",
    "                    q_circuits[j], (all_params[0][j], all_params[1][j]), feature_vec\n",
    "                )\n",
    "                s_j = s_j.float()\n",
    "                li += torch.max(torch.zeros(1).float(), s_j - s_true + margin)\n",
    "        loss += li\n",
    "\n",
    "    return loss / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(q_circuits, all_params, feature_vecs, labels):\n",
    "    predicted_labels = []\n",
    "    for i, feature_vec in enumerate(feature_vecs):\n",
    "        scores = np.zeros(num_classes)\n",
    "        for c in range(num_classes):\n",
    "            score = variational_classifier(\n",
    "                q_circuits[c], (all_params[0][c], all_params[1][c]), feature_vec\n",
    "            )\n",
    "            scores[c] = float(score)\n",
    "        pred_class = np.argmax(scores)\n",
    "        predicted_labels.append(pred_class)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, hard_predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, hard_predictions):\n",
    "        if torch.abs(l - p) < 1e-5:\n",
    "            loss = loss + 1\n",
    "    loss = loss / labels.shape[0]\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  111\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[87, 70] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 52\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# We now run our training algorithm and plot the results. Note that\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# for plotting, the matplotlib library is required\u001b[39;00m\n\u001b[0;32m     51\u001b[0m features, Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]),np\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 52\u001b[0m costs, train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     56\u001b[0m fig, ax1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n",
      "Cell \u001b[1;32mIn[23], line 23\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(features, Y)\u001b[0m\n\u001b[0;32m     21\u001b[0m batch_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_train, (batch_size,))\n\u001b[0;32m     22\u001b[0m feat_vecs_train_batch \u001b[38;5;241m=\u001b[39m feat_vecs_train[batch_index]\n\u001b[1;32m---> 23\u001b[0m Y_train_batch \u001b[38;5;241m=\u001b[39m \u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     26\u001b[0m curr_cost \u001b[38;5;241m=\u001b[39m multiclass_svm_loss(q_circuits, params, feat_vecs_train_batch, Y_train_batch)\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1099\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1102\u001b[0m             \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1108\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1109\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1517\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1518\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1520\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fayne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[87, 70] not in index'"
     ]
    }
   ],
   "source": [
    "def training(features, Y):\n",
    "    num_data = Y.shape[0]\n",
    "    feat_vecs_train, feat_vecs_test, Y_train, Y_test = X_train, X_test, y_train, y_test\n",
    "    num_train = Y_train.shape[0]\n",
    "    q_circuits = qnodes\n",
    "\n",
    "    # Initialize the parameters\n",
    "    all_weights = [\n",
    "        Variable(0.1 * torch.randn(num_layers, num_qubits, 3), requires_grad=True)\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "    all_bias = [Variable(0.1 * torch.ones(1), requires_grad=True) for i in range(num_classes)]\n",
    "    optimizer = optim.Adam(all_weights + all_bias, lr=lr_adam)\n",
    "    params = (all_weights, all_bias)\n",
    "    print(\"Num params: \", 3 * num_layers * num_qubits * 3 + 3)\n",
    "\n",
    "    costs, train_acc, test_acc = [], [], []\n",
    "\n",
    "    # train the variational classifier\n",
    "    for it in range(total_iterations):\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feat_vecs_train_batch = feat_vecs_train[batch_index]\n",
    "        Y_train_batch = Y_train[batch_index]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        curr_cost = multiclass_svm_loss(q_circuits, params, feat_vecs_train_batch, Y_train_batch)\n",
    "        curr_cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        predictions_train = classify(q_circuits, params, feat_vecs_train, Y_train)\n",
    "        predictions_test = classify(q_circuits, params, feat_vecs_test, Y_test)\n",
    "        acc_train = accuracy(Y_train, predictions_train)\n",
    "        acc_test = accuracy(Y_test, predictions_test)\n",
    "\n",
    "        print(\n",
    "            \"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc test: {:0.7f} \"\n",
    "            \"\".format(it + 1, curr_cost.item(), acc_train, acc_test)\n",
    "        )\n",
    "\n",
    "        costs.append(curr_cost.item())\n",
    "        train_acc.append(acc_train)\n",
    "        test_acc.append(acc_test)\n",
    "\n",
    "    return costs, train_acc, test_acc\n",
    "\n",
    "\n",
    "# We now run our training algorithm and plot the results. Note that\n",
    "# for plotting, the matplotlib library is required\n",
    "\n",
    "features, Y = np.asarray([0,0]),np.asarray([0])\n",
    "costs, train_acc, test_acc = training(features, Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "iters = np.arange(0, total_iterations, 1)\n",
    "colors = [\"tab:red\", \"tab:blue\"]\n",
    "ax1.set_xlabel(\"Iteration\", fontsize=17)\n",
    "ax1.set_ylabel(\"Cost\", fontsize=17, color=colors[0])\n",
    "ax1.plot(iters, costs, color=colors[0], linewidth=4)\n",
    "ax1.tick_params(axis=\"y\", labelsize=14, labelcolor=colors[0])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Test Acc.\", fontsize=17, color=colors[1])\n",
    "ax2.plot(iters, test_acc, color=colors[1], linewidth=4)\n",
    "\n",
    "ax2.tick_params(axis=\"x\", labelsize=14)\n",
    "ax2.tick_params(axis=\"y\", labelsize=14, labelcolor=colors[1])\n",
    "\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params:  250\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:24\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
